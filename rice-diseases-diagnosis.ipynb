{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\ntf.__version__","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-16T10:54:45.374783Z","iopub.execute_input":"2021-09-16T10:54:45.375534Z","iopub.status.idle":"2021-09-16T10:54:51.343554Z","shell.execute_reply.started":"2021-09-16T10:54:45.375426Z","shell.execute_reply":"2021-09-16T10:54:51.342737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\n\nimport cv2\n\nimport albumentations as albu\nfrom albumentations import Compose, ShiftScaleRotate, Resize\nfrom albumentations.pytorch import ToTensor\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nfrom sklearn.metrics import classification_report\n\nimport shutil\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-09-16T10:54:51.344782Z","iopub.execute_input":"2021-09-16T10:54:51.345271Z","iopub.status.idle":"2021-09-16T10:54:54.651875Z","shell.execute_reply.started":"2021-09-16T10:54:51.345220Z","shell.execute_reply":"2021-09-16T10:54:54.650921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_HEIGHT = 224\nIMAGE_WIDTH = 224\nIMAGE_CHANNELS = 3","metadata":{"execution":{"iopub.status.busy":"2021-09-16T10:54:54.653376Z","iopub.execute_input":"2021-09-16T10:54:54.653981Z","iopub.status.idle":"2021-09-16T10:54:54.658009Z","shell.execute_reply.started":"2021-09-16T10:54:54.653948Z","shell.execute_reply":"2021-09-16T10:54:54.656960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(\"../input/rice-diseases-image-dataset/LabelledRice/Labelled\")","metadata":{"execution":{"iopub.status.busy":"2021-09-16T10:54:54.659093Z","iopub.execute_input":"2021-09-16T10:54:54.659613Z","iopub.status.idle":"2021-09-16T10:54:54.691656Z","shell.execute_reply.started":"2021-09-16T10:54:54.659529Z","shell.execute_reply":"2021-09-16T10:54:54.690491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"brownspot_list = \\\nos.listdir('../input/rice-diseases-image-dataset/LabelledRice/Labelled/BrownSpot')\nhealthy_list = \\\nos.listdir('../input/rice-diseases-image-dataset/LabelledRice/Labelled/Healthy')\nhispa_list = \\\nos.listdir('../input/rice-diseases-image-dataset/LabelledRice/Labelled/Hispa')\nLeafBlast_list = \\\nos.listdir('../input/rice-diseases-image-dataset/LabelledRice/Labelled/LeafBlast')\n\nprint(len(brownspot_list))\nprint(len(healthy_list))\nprint(len(hispa_list))\nprint(len(LeafBlast_list))","metadata":{"execution":{"iopub.status.busy":"2021-09-16T10:54:54.693040Z","iopub.execute_input":"2021-09-16T10:54:54.693468Z","iopub.status.idle":"2021-09-16T10:54:55.918021Z","shell.execute_reply.started":"2021-09-16T10:54:54.693423Z","shell.execute_reply":"2021-09-16T10:54:55.916830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_brownspot = pd.DataFrame(brownspot_list, columns=['image'])\ndf_brownspot['target'] = 'brownspot'\n\ndf_healthy = pd.DataFrame(healthy_list, columns=['image'])\ndf_healthy['target'] = 'healthy'\n\ndf_hispa = pd.DataFrame(hispa_list, columns=['image'])\ndf_hispa['target'] = 'hispa'\ndf_LeafBlast = pd.DataFrame(LeafBlast_list, columns=['image'])\ndf_LeafBlast['target'] = 'LeafBlast'\n\n\n# Create a val set for each class\n\n# Sample 5 validation images from each class\ndf_brownspot_val = df_brownspot.sample(n=105, random_state=500)\ndf_healthy_val = df_healthy.sample(n=297, random_state=500)\ndf_hispa_val = df_hispa.sample(n=113, random_state=500)\ndf_LeafBlast_val = df_LeafBlast.sample(n=155, random_state=500)\n\n\nprint(len(df_brownspot_val))\nprint(len(df_healthy_val))\nprint(len(df_hispa_val))\nprint(len(df_LeafBlast_val))","metadata":{"execution":{"iopub.status.busy":"2021-09-16T10:55:45.453361Z","iopub.execute_input":"2021-09-16T10:55:45.453714Z","iopub.status.idle":"2021-09-16T10:55:45.471858Z","shell.execute_reply.started":"2021-09-16T10:55:45.453680Z","shell.execute_reply":"2021-09-16T10:55:45.470581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get a list of val images\nval_list = list(df_brownspot_val['image'])\n# filter out the val images\ndf_brownspot_train = df_brownspot[~df_brownspot['image'].isin(val_list)] # ~ means notin\n\n# brown_spot\n# get a list of val images\nval_list = list(df_healthy_val['image'])\n# filter out the val images\ndf_healthy_train = df_healthy[~df_healthy['image'].isin(val_list)] # ~ means notin\n\n# bacterial_leaf_blight\n# get a list of val images\nval_list = list(df_hispa_val['image'])\n# filter out the val images\ndf_hispa_train = \\\ndf_hispa[~df_hispa['image'].isin(val_list)] # ~ means notin\n#////////////////////////////////\nval_list = list(df_LeafBlast_val['image'])\n# filter out the val images\ndf_LeafBlast_train = \\\ndf_LeafBlast[~df_LeafBlast['image'].isin(val_list)] # ~ means notin\n\nprint(len(df_brownspot_train ))\nprint(len(df_healthy_train))\nprint(len(df_hispa_train))\nprint(len(df_LeafBlast_train))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-16T10:55:50.694099Z","iopub.execute_input":"2021-09-16T10:55:50.694516Z","iopub.status.idle":"2021-09-16T10:55:50.709482Z","shell.execute_reply.started":"2021-09-16T10:55:50.694482Z","shell.execute_reply":"2021-09-16T10:55:50.708384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf_data = pd.concat([df_brownspot, df_healthy, df_hispa,df_LeafBlast], axis=0).reset_index(drop=True)\n\ndf_train = \\\npd.concat([df_brownspot_train, df_healthy_train, df_hispa_train,df_LeafBlast_train], axis=0).reset_index(drop=True)\n\ndf_val = \\\npd.concat([df_brownspot_val, df_healthy_val, df_hispa_val,df_LeafBlast_val], axis=0).reset_index(drop=True)\n\ndf_data = shuffle(df_data)\ndf_train = shuffle(df_train)\ndf_val = shuffle(df_val)\n\nprint(df_data.shape)\nprint(df_train.shape)\nprint(df_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-16T11:03:18.976316Z","iopub.execute_input":"2021-09-16T11:03:18.976651Z","iopub.status.idle":"2021-09-16T11:03:18.991176Z","shell.execute_reply.started":"2021-09-16T11:03:18.976622Z","shell.execute_reply":"2021-09-16T11:03:18.990320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_data['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-16T11:03:52.393902Z","iopub.execute_input":"2021-09-16T11:03:52.394226Z","iopub.status.idle":"2021-09-16T11:03:52.404090Z","shell.execute_reply.started":"2021-09-16T11:03:52.394197Z","shell.execute_reply":"2021-09-16T11:03:52.403445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:51:09.041816Z","iopub.execute_input":"2021-07-06T14:51:09.042248Z","iopub.status.idle":"2021-07-06T14:51:09.053542Z","shell.execute_reply.started":"2021-07-06T14:51:09.042217Z","shell.execute_reply":"2021-07-06T14:51:09.052615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:51:09.054543Z","iopub.execute_input":"2021-07-06T14:51:09.054808Z","iopub.status.idle":"2021-07-06T14:51:09.066272Z","shell.execute_reply.started":"2021-07-06T14:51:09.054785Z","shell.execute_reply":"2021-07-06T14:51:09.065361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_len = len(df_val)\ntrain_len = len(df_train)\ndf_combined =  pd.concat(objs=[df_val, df_train], axis=0).reset_index(drop=True)\n\n# create the dummy variables\ndf_combined = pd.get_dummies(df_combined, columns=['target'])\n\n# separate the train and val sets\ndf_val = df_combined[:val_len]\ndf_train = df_combined[val_len:]\n\n\nprint(df_train.shape)\nprint(df_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:51:09.067824Z","iopub.execute_input":"2021-07-06T14:51:09.068087Z","iopub.status.idle":"2021-07-06T14:51:09.085428Z","shell.execute_reply.started":"2021-07-06T14:51:09.068063Z","shell.execute_reply":"2021-07-06T14:51:09.084703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_len = len(df_val)\ntrain_len = len(df_train)\ndf_combined =  pd.concat(objs=[df_val, df_train], axis=0).reset_index(drop=True)\n​\n# create the dummy variables\ndf_combined = pd.get_dummies(df_combined, columns=['target'])\n​\n# separate the train and val sets\ndf_val = df_combined[:val_len]\ndf_train = df_combined[val_len:]\n​\n​\nprint(df_train.shape)\nprint(df_val.shape)df_combined.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:51:09.086558Z","iopub.execute_input":"2021-07-06T14:51:09.086948Z","iopub.status.idle":"2021-07-06T14:51:09.101922Z","shell.execute_reply.started":"2021-07-06T14:51:09.086913Z","shell.execute_reply":"2021-07-06T14:51:09.10122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:51:09.103133Z","iopub.execute_input":"2021-07-06T14:51:09.103459Z","iopub.status.idle":"2021-07-06T14:51:09.113303Z","shell.execute_reply.started":"2021-07-06T14:51:09.103426Z","shell.execute_reply":"2021-07-06T14:51:09.112228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:51:09.114808Z","iopub.execute_input":"2021-07-06T14:51:09.115246Z","iopub.status.idle":"2021-07-06T14:51:09.126974Z","shell.execute_reply.started":"2021-07-06T14:51:09.115209Z","shell.execute_reply":"2021-07-06T14:51:09.12611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_combined.to_csv('df_combined.csv.gz', compression='gzip', index=False)\n\ndf_train.to_csv('df_train.csv.gz', compression='gzip', index=False)\ndf_val.to_csv('df_val.csv.gz', compression='gzip', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:51:09.128052Z","iopub.execute_input":"2021-07-06T14:51:09.128534Z","iopub.status.idle":"2021-07-06T14:51:09.415527Z","shell.execute_reply.started":"2021-07-06T14:51:09.128498Z","shell.execute_reply":"2021-07-06T14:51:09.414752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:51:09.416743Z","iopub.execute_input":"2021-07-06T14:51:09.417087Z","iopub.status.idle":"2021-07-06T14:51:10.071443Z","shell.execute_reply.started":"2021-07-06T14:51:09.417049Z","shell.execute_reply":"2021-07-06T14:51:10.070534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new directory\nimage_dir = 'image_dir'\nos.mkdir(image_dir)\n\n!ls","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:51:10.072815Z","iopub.execute_input":"2021-07-06T14:51:10.073151Z","iopub.status.idle":"2021-07-06T14:51:10.853047Z","shell.execute_reply.started":"2021-07-06T14:51:10.07311Z","shell.execute_reply":"2021-07-06T14:51:10.852087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(os.listdir('image_dir'))","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:20.609564Z","iopub.execute_input":"2021-07-06T14:53:20.609902Z","iopub.status.idle":"2021-07-06T14:53:20.620993Z","shell.execute_reply.started":"2021-07-06T14:53:20.609868Z","shell.execute_reply":"2021-07-06T14:53:20.620099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as albu\n\n\ndef augment_image(augmentation, image):\n    \n    \"\"\"\n    Uses the Albumentations library.\n    \n    Inputs: \n    1. augmentation - this is the instance of type of augmentation to do \n    e.g. aug_type = HorizontalFlip(p=1) \n    # p=1 is the probability of the transform being executed.\n    \n    2. image - image with shape (h,w)\n    \n    Output:\n    Augmented image as a numpy array.\n    \n    \"\"\"\n    # get the transform as a dict\n    aug_image_dict =  augmentation(image=image)\n    # retrieve the augmented matrix of the image\n    image_matrix = aug_image_dict['image']\n    \n    \n    return image_matrix","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:20.62222Z","iopub.execute_input":"2021-07-06T14:53:20.622544Z","iopub.status.idle":"2021-07-06T14:53:21.20158Z","shell.execute_reply.started":"2021-07-06T14:53:20.622511Z","shell.execute_reply":"2021-07-06T14:53:21.199925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the transforms\n\n\naug_types = albu.Compose([\n            albu.HorizontalFlip(),\n             albu.OneOf([\n                albu.HorizontalFlip(),\n                albu.VerticalFlip(),\n                ], p=0.8),\n            albu.OneOf([\n                albu.RandomContrast(),\n                albu.RandomGamma(),\n                albu.RandomBrightness(),\n                ], p=0.3),\n            albu.OneOf([\n                albu.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n                albu.GridDistortion(),\n                albu.OpticalDistortion(distort_limit=2, shift_limit=0.5),\n                ], p=0.3),\n            albu.ShiftScaleRotate()\n            ])","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:21.219209Z","iopub.execute_input":"2021-07-06T14:53:21.221557Z","iopub.status.idle":"2021-07-06T14:53:21.236483Z","shell.execute_reply.started":"2021-07-06T14:53:21.221508Z","shell.execute_reply":"2021-07-06T14:53:21.235521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get an image to test transformations\n\n# get a list of train png images\npath = 'image_dir/'\nimage_list = os.listdir('image_dir')\n\nfname = image_list[1]\nimage_path = path + fname\n\nimage = plt.imread(image_path)\nplt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:21.245127Z","iopub.execute_input":"2021-07-06T14:53:21.247412Z","iopub.status.idle":"2021-07-06T14:53:21.73054Z","shell.execute_reply.started":"2021-07-06T14:53:21.247367Z","shell.execute_reply":"2021-07-06T14:53:21.7297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test the transformation setup.\n# The image will be different each time this cell is run.\n\naug_image = augment_image(aug_types, image)\n\nplt.imshow(aug_image)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:21.731643Z","iopub.execute_input":"2021-07-06T14:53:21.731962Z","iopub.status.idle":"2021-07-06T14:53:22.057302Z","shell.execute_reply.started":"2021-07-06T14:53:21.731925Z","shell.execute_reply":"2021-07-06T14:53:22.056477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:22.058446Z","iopub.execute_input":"2021-07-06T14:53:22.058858Z","iopub.status.idle":"2021-07-06T14:53:22.070837Z","shell.execute_reply.started":"2021-07-06T14:53:22.058824Z","shell.execute_reply":"2021-07-06T14:53:22.06995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_generator(batch_size=8):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_train.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image'])\n            \n            # Create empty X matrix - 3 channels\n            X_train = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n            \n            \n        \n            \n            # Create X_train\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i]\n\n\n                # set the path to the image\n                path = 'image_dir/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n                \n                \n                 # Create y_train\n            # ===============\n                cols = ['target_brownspot', 'target_healthy', 'target_hispa','target_LeafBlast']\n                y_train = df[cols]\n                y_train = np.asarray(y_train) \n\n                # change the shape to (batch_size, 1)\n                #y_train = y_train.reshape((-1, 1)) # -1 tells numpy to automatically detect the batch size\n       \n              \n            # Augment the image and mask\n            # ===========================\n\n                aug_image = augment_image(aug_types, image)\n              \n                # insert the image into X_train\n                X_train[i] = aug_image\n                \n                          \n                \n            # Normalize the images\n            X_train = X_train/255\n\n            yield X_train, y_train","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:22.07244Z","iopub.execute_input":"2021-07-06T14:53:22.072823Z","iopub.status.idle":"2021-07-06T14:53:22.083169Z","shell.execute_reply.started":"2021-07-06T14:53:22.072785Z","shell.execute_reply":"2021-07-06T14:53:22.082124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test the generator\n\n# initialize\ntrain_gen = train_generator(batch_size=8)\n\n# run the generator\nX_train, y_train = next(train_gen)\n\nprint(X_train.shape)\nprint(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:22.084614Z","iopub.execute_input":"2021-07-06T14:53:22.085007Z","iopub.status.idle":"2021-07-06T14:53:23.036595Z","shell.execute_reply.started":"2021-07-06T14:53:22.084934Z","shell.execute_reply":"2021-07-06T14:53:23.035708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:23.037772Z","iopub.execute_input":"2021-07-06T14:53:23.038117Z","iopub.status.idle":"2021-07-06T14:53:23.043718Z","shell.execute_reply.started":"2021-07-06T14:53:23.038075Z","shell.execute_reply":"2021-07-06T14:53:23.042908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the first image in X_train\n# Remember that train images have been augmented.\n\nimage = X_train[0,:,:,:]\nplt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:23.045055Z","iopub.execute_input":"2021-07-06T14:53:23.045623Z","iopub.status.idle":"2021-07-06T14:53:23.213659Z","shell.execute_reply.started":"2021-07-06T14:53:23.045568Z","shell.execute_reply":"2021-07-06T14:53:23.21269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val_generator(batch_size=5):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_val.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image'])\n            \n            # Create empty X matrix - 3 channels\n            X_val = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_val\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i]\n                \n\n                # set the path to the image\n                path = 'image_dir/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n\n                # insert the image into X_train\n                X_val[i] = image\n                \n                \n            \n            \n            # Create y_val\n            # ===============\n            \n                cols = ['target_brownspot', 'target_healthy', 'target_hispa','target_LeafBlast']\n                y_val = df[cols]\n                y_val = np.asarray(y_val) \n\n                # change the shape to (batch_size, 1)\n                #y_val = y_val.reshape((-1, 1)) # -1 tells numpy to automatically detect the batch size\n       \n            \n                \n                          \n                \n            # Normalize the images\n            X_val = X_val/255\n\n            yield X_val, y_val","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:23.215112Z","iopub.execute_input":"2021-07-06T14:53:23.215439Z","iopub.status.idle":"2021-07-06T14:53:23.223886Z","shell.execute_reply.started":"2021-07-06T14:53:23.215405Z","shell.execute_reply":"2021-07-06T14:53:23.222954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test the generator\n\n# initialize\nval_gen = val_generator(batch_size=5)\n\n# run the generator\nX_val, y_val = next(val_gen)\n\nprint(X_val.shape)\nprint(y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:23.225205Z","iopub.execute_input":"2021-07-06T14:53:23.225753Z","iopub.status.idle":"2021-07-06T14:53:23.658537Z","shell.execute_reply.started":"2021-07-06T14:53:23.225715Z","shell.execute_reply":"2021-07-06T14:53:23.657699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_val","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:23.659739Z","iopub.execute_input":"2021-07-06T14:53:23.660084Z","iopub.status.idle":"2021-07-06T14:53:23.668203Z","shell.execute_reply.started":"2021-07-06T14:53:23.660047Z","shell.execute_reply":"2021-07-06T14:53:23.66752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print the image from X_val\nimage = X_val[0,:,:,:]\nplt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:23.669753Z","iopub.execute_input":"2021-07-06T14:53:23.670559Z","iopub.status.idle":"2021-07-06T14:53:23.83433Z","shell.execute_reply.started":"2021-07-06T14:53:23.670519Z","shell.execute_reply":"2021-07-06T14:53:23.83353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_generator(batch_size=1):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_val.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image'])\n            \n            # Create empty X matrix - 3 channels\n            X_test = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_test\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i]\n                \n\n                # set the path to the image\n                path = 'image_dir/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n\n                # insert the image into X_train\n                X_test[i] = image\n                \n                 \n                \n            # Normalize the images\n            X_test = X_test/255\n\n            yield X_test","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:23.835611Z","iopub.execute_input":"2021-07-06T14:53:23.836107Z","iopub.status.idle":"2021-07-06T14:53:23.844052Z","shell.execute_reply.started":"2021-07-06T14:53:23.836057Z","shell.execute_reply":"2021-07-06T14:53:23.843195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test the generator\n\n# initialize\ntest_gen = test_generator(batch_size=1)\n\n# run the generator\nX_test = next(test_gen)\n\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:23.845251Z","iopub.execute_input":"2021-07-06T14:53:23.845595Z","iopub.status.idle":"2021-07-06T14:53:23.895269Z","shell.execute_reply.started":"2021-07-06T14:53:23.84556Z","shell.execute_reply":"2021-07-06T14:53:23.89443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print the image from X_test\n\nimage = X_test[0,:,:,:]\nplt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:23.896611Z","iopub.execute_input":"2021-07-06T14:53:23.896948Z","iopub.status.idle":"2021-07-06T14:53:24.062497Z","shell.execute_reply.started":"2021-07-06T14:53:23.896913Z","shell.execute_reply":"2021-07-06T14:53:24.061545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\nfrom tensorflow.keras.metrics import categorical_accuracy\n\nfrom tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n                                        ModelCheckpoint, CSVLogger, LearningRateScheduler)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:24.064055Z","iopub.execute_input":"2021-07-06T14:53:24.064392Z","iopub.status.idle":"2021-07-06T14:53:24.07061Z","shell.execute_reply.started":"2021-07-06T14:53:24.064355Z","shell.execute_reply":"2021-07-06T14:53:24.069492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.mobilenet import MobileNet\n\nmodel = MobileNet(weights='imagenet')\n\n# Exclude the last 2 layers of the above model.\nx = model.layers[-2].output\n\n# Create a new dense layer for predictions\n# 3 corresponds to the number of classes\npredictions = Dense(4, activation='softmax')(x)\n\n# inputs=model.input selects the input layer, outputs=predictions refers to the\n# dense layer we created above.\n\nmodel = Model(inputs=model.input, outputs=predictions)\n\nmodel.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_BATCH_SIZE = 8\nVAL_BATCH_SIZE = 5\n\nnum_train_samples = len(df_train)\nnum_val_samples = len(df_val)\ntrain_batch_size = TRAIN_BATCH_SIZE\nval_batch_size = VAL_BATCH_SIZE\n\n# determine numtrain steps\ntrain_steps = np.ceil(num_train_samples / train_batch_size)\n# determine num val steps\nval_steps = np.ceil(num_val_samples / val_batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:31.993925Z","iopub.execute_input":"2021-07-06T14:53:31.994194Z","iopub.status.idle":"2021-07-06T14:53:31.998489Z","shell.execute_reply.started":"2021-07-06T14:53:31.994167Z","shell.execute_reply":"2021-07-06T14:53:31.997684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the generators\ntrain_gen = train_generator(batch_size=TRAIN_BATCH_SIZE)\nval_gen = val_generator(batch_size=VAL_BATCH_SIZE)\n\nmodel.compile(\n    Adam(lr=0.0001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy'],\n)\n\n\n\nfilepath = \"model.h5\"\n\n#earlystopper = EarlyStopping(patience=10, verbose=1)\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, \n                             save_best_only=True, mode='max')\n\n#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, \n                                   #verbose=1, mode='min')\n\n\n\nlog_fname = 'training_log.csv'\ncsv_logger = CSVLogger(filename=log_fname,\n                       separator=',',\n                       append=False)\n\ncallbacks_list = [checkpoint, csv_logger]\n\nhistory = model.fit_generator(train_gen, steps_per_epoch=train_steps, epochs=50, \n                              validation_data=val_gen, validation_steps=val_steps,\n                             verbose=1,callbacks=callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:31.999834Z","iopub.execute_input":"2021-07-06T14:53:32.000236Z","iopub.status.idle":"2021-07-06T21:32:06.10737Z","shell.execute_reply.started":"2021-07-06T14:53:32.000202Z","shell.execute_reply":"2021-07-06T21:32:06.103691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the training log\n\ntrain_log = pd.read_csv('training_log.csv')\n\ntrain_log.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T21:32:06.113496Z","iopub.execute_input":"2021-07-06T21:32:06.113787Z","iopub.status.idle":"2021-07-06T21:32:06.143705Z","shell.execute_reply.started":"2021-07-06T21:32:06.113754Z","shell.execute_reply":"2021-07-06T21:32:06.142996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the metric names so we can use evaulate_generator\nmodel.metrics_names","metadata":{"execution":{"iopub.status.busy":"2021-07-06T21:32:06.144657Z","iopub.execute_input":"2021-07-06T21:32:06.144906Z","iopub.status.idle":"2021-07-06T21:32:06.167133Z","shell.execute_reply.started":"2021-07-06T21:32:06.144881Z","shell.execute_reply":"2021-07-06T21:32:06.166319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('model.h5')\n\nval_gen = val_generator(batch_size=1)\n\nval_loss, val_acc = \\\nmodel.evaluate_generator(val_gen, \n                        steps=len(df_val))\n\nprint('val_loss:', val_loss)\nprint('val_acc:', val_acc)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T21:32:06.168372Z","iopub.execute_input":"2021-07-06T21:32:06.168733Z","iopub.status.idle":"2021-07-06T21:33:14.493523Z","shell.execute_reply.started":"2021-07-06T21:32:06.168685Z","shell.execute_reply":"2021-07-06T21:33:14.492681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_gen = test_generator(batch_size=1)\n\npreds = model.predict_generator(test_gen, steps=len(df_val), verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T21:33:14.496084Z","iopub.execute_input":"2021-07-06T21:33:14.496371Z","iopub.status.idle":"2021-07-06T21:34:23.213924Z","shell.execute_reply.started":"2021-07-06T21:33:14.496342Z","shell.execute_reply":"2021-07-06T21:34:23.213166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get y_pred as index values\n\ny_pred = np.argmax(preds, axis=1)\n\ny_pred","metadata":{"execution":{"iopub.status.busy":"2021-07-06T21:34:23.215679Z","iopub.execute_input":"2021-07-06T21:34:23.216034Z","iopub.status.idle":"2021-07-06T21:34:23.225728Z","shell.execute_reply.started":"2021-07-06T21:34:23.215997Z","shell.execute_reply":"2021-07-06T21:34:23.224831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get y_true as index values\n\ncols = ['target_brownspot', 'target_healthy', 'target_hispa','target_LeafBlast']\ny_true = df_val[cols]\ny_true = np.asarray(y_true) \n\ny_true = np.argmax(y_true, axis=1)\n\ny_true","metadata":{"execution":{"iopub.status.busy":"2021-07-06T21:34:23.22703Z","iopub.execute_input":"2021-07-06T21:34:23.227525Z","iopub.status.idle":"2021-07-06T21:34:23.240182Z","shell.execute_reply.started":"2021-07-06T21:34:23.227483Z","shell.execute_reply":"2021-07-06T21:34:23.239424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare y_true and y_pred\n\nprint(y_pred)\nprint(y_true)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-06T21:34:23.241349Z","iopub.execute_input":"2021-07-06T21:34:23.241704Z","iopub.status.idle":"2021-07-06T21:34:23.250258Z","shell.execute_reply.started":"2021-07-06T21:34:23.241661Z","shell.execute_reply":"2021-07-06T21:34:23.249261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nlabels ='brown spot','healthy','hispa','leafblast'\nsize=[len(df_brownspot_train ),len(df_healthy_train ),len(df_hispa_train),len(df_LeafBlast_train)]\nexplode=(0,0.1,0,0)\nfig1,ax1=plt.subplots()\nax1.pie(size,explode=explode,labels=labels,autopct='%1.1f%%',shadow=True,startangle=90)\nax1.axis('equal')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T21:34:23.251499Z","iopub.execute_input":"2021-07-06T21:34:23.252133Z","iopub.status.idle":"2021-07-06T21:34:23.411134Z","shell.execute_reply.started":"2021-07-06T21:34:23.252096Z","shell.execute_reply":"2021-07-06T21:34:23.410233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport itertools\n\ncm = confusion_matrix(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T21:34:23.412381Z","iopub.execute_input":"2021-07-06T21:34:23.41281Z","iopub.status.idle":"2021-07-06T21:34:23.422483Z","shell.execute_reply.started":"2021-07-06T21:34:23.412734Z","shell.execute_reply":"2021-07-06T21:34:23.421658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# bacterial_leaf_blight = 0\n# brown_spot = 1\n# leaf_smut = 2\n\ncm_plot_labels = ['brownspot', 'healthy', 'hispa','LeafBlast']\n\nplot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')","metadata":{"execution":{"iopub.status.busy":"2021-07-06T21:34:23.423782Z","iopub.execute_input":"2021-07-06T21:34:23.424379Z","iopub.status.idle":"2021-07-06T21:34:23.678408Z","shell.execute_reply.started":"2021-07-06T21:34:23.424339Z","shell.execute_reply":"2021-07-06T21:34:23.677662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Generate a classification report\nreport = classification_report(y_true, y_pred, target_names=['brownspot', 'healthy', 'hispa','LeafBlast'])\n\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T21:34:23.679604Z","iopub.execute_input":"2021-07-06T21:34:23.679923Z","iopub.status.idle":"2021-07-06T21:34:23.692055Z","shell.execute_reply.started":"2021-07-06T21:34:23.679887Z","shell.execute_reply":"2021-07-06T21:34:23.691133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# --ignore-installed is added to fix an error.\n\n# https://stackoverflow.com/questions/49932759/pip-10-and-apt-how-to-avoid-cannot-uninstall\n# -x-errors-for-distutils-packages\n\n!pip install tensorflowjs --ignore-installed","metadata":{"execution":{"iopub.status.busy":"2021-07-06T21:34:23.693446Z","iopub.execute_input":"2021-07-06T21:34:23.693797Z","iopub.status.idle":"2021-07-06T21:35:34.139094Z","shell.execute_reply.started":"2021-07-06T21:34:23.693762Z","shell.execute_reply":"2021-07-06T21:35:34.138152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use the command line conversion tool to convert the model\n\n!tensorflowjs_converter --input_format keras model.h5 tfjs/model","metadata":{"execution":{"iopub.status.busy":"2021-07-06T21:35:34.140712Z","iopub.execute_input":"2021-07-06T21:35:34.141065Z","iopub.status.idle":"2021-07-06T21:35:38.43169Z","shell.execute_reply.started":"2021-07-06T21:35:34.141022Z","shell.execute_reply":"2021-07-06T21:35:38.430676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2021-07-06T21:35:38.433229Z","iopub.execute_input":"2021-07-06T21:35:38.43356Z","iopub.status.idle":"2021-07-06T21:35:39.135395Z","shell.execute_reply.started":"2021-07-06T21:35:38.43352Z","shell.execute_reply":"2021-07-06T21:35:39.134435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Delete the test_dir directory we created to prevent a Kaggle error.\n# Kaggle allows a max of 500 files to be saved.\n\nshutil.rmtree('image_dir')","metadata":{"execution":{"iopub.status.busy":"2021-07-06T21:35:39.136889Z","iopub.execute_input":"2021-07-06T21:35:39.137219Z","iopub.status.idle":"2021-07-06T21:35:39.77515Z","shell.execute_reply.started":"2021-07-06T21:35:39.137187Z","shell.execute_reply":"2021-07-06T21:35:39.774237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2021-07-06T21:35:39.7766Z","iopub.execute_input":"2021-07-06T21:35:39.776974Z","iopub.status.idle":"2021-07-06T21:35:40.478469Z","shell.execute_reply.started":"2021-07-06T21:35:39.776935Z","shell.execute_reply":"2021-07-06T21:35:40.477432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nlabels ='brown spot','healthy','hispa','leafblast'\nsize=[len(df_brownspot_val ),len(df_healthy_val ),len(df_hispa_val),len(df_LeafBlast_val)]\nexplode=(0,0.1,0,0)\nfig1,ax1=plt.subplots()\nax1.pie(size,explode=explode,labels=labels,autopct='%1.1f%%',shadow=True,startangle=90)\nax1.axis('equal')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T21:35:40.480229Z","iopub.execute_input":"2021-07-06T21:35:40.48063Z","iopub.status.idle":"2021-07-06T21:35:40.601664Z","shell.execute_reply.started":"2021-07-06T21:35:40.480585Z","shell.execute_reply":"2021-07-06T21:35:40.600921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show() \n","metadata":{"execution":{"iopub.status.busy":"2021-07-06T21:35:40.602925Z","iopub.execute_input":"2021-07-06T21:35:40.603259Z","iopub.status.idle":"2021-07-06T21:35:40.889218Z","shell.execute_reply.started":"2021-07-06T21:35:40.603225Z","shell.execute_reply":"2021-07-06T21:35:40.888193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}